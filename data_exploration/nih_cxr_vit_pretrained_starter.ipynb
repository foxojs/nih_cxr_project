{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/ojf24/home/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from tqdm import trange, tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import os \n",
    "from PIL import Image\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling torch-1.1.0:\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/shutil.py\", line 550, in move\n",
      "    os.rename(src, real_dst)\n",
      "OSError: [Errno 18] Invalid cross-device link: '/rds/general/applications/jupyterhub/2019-04-29/miniconda/lib/python3.6/site-packages/caffe2' -> '/var/tmp/pbs.863968.pbs/pip-uninstall-rz6zdgtu'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/site-packages/pip/_internal/cli/base_command.py\", line 178, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/site-packages/pip/_internal/commands/uninstall.py\", line 75, in run\n",
      "    auto_confirm=options.yes, verbose=self.verbosity > 0,\n",
      "  File \"/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/site-packages/pip/_internal/req/req_install.py\", line 825, in uninstall\n",
      "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
      "  File \"/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/site-packages/pip/_internal/req/req_uninstall.py\", line 388, in remove\n",
      "    moved.stash(path)\n",
      "  File \"/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/site-packages/pip/_internal/req/req_uninstall.py\", line 277, in stash\n",
      "    renames(path, new_path)\n",
      "  File \"/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/site-packages/pip/_internal/utils/misc.py\", line 305, in renames\n",
      "    shutil.move(old, new)\n",
      "  File \"/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/shutil.py\", line 562, in move\n",
      "    rmtree(src)\n",
      "  File \"/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/shutil.py\", line 486, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onerror)\n",
      "  File \"/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/shutil.py\", line 424, in _rmtree_safe_fd\n",
      "    _rmtree_safe_fd(dirfd, fullname, onerror)\n",
      "  File \"/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/shutil.py\", line 444, in _rmtree_safe_fd\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"/apps/jupyterhub/2019-04-29/miniconda/lib/python3.6/shutil.py\", line 442, in _rmtree_safe_fd\n",
      "    os.unlink(name, dir_fd=topfd)\n",
      "PermissionError: [Errno 13] Permission denied: '__init__.py'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = load_dataset(\"alkzar90/NIH-Chest-X-ray-dataset\", 'image-classification', split = \"train[:5000]\") \n",
    "\n",
    "# we hold back our test data to be used purely for testing, not in the context of our training loop \n",
    "ds_test = load_dataset(\"alkzar90/NIH-Chest-X-ray-dataset\", 'image-classification', split = \"test[:2000]\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from torch import optim \n",
    "\n",
    "from transformers import ViTForImageClassification\n",
    "import torchmetrics \n",
    "\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue using pytorch ligthing to fine tune model as per \n",
    "\n",
    "# https://towardsdatascience.com/how-to-fine-tune-a-pretrained-vision-transformer-on-satellite-data-d0ddd8359596/#:~:text=Under%20the%20hood%2C%20the%20trainer,is%20completed%20within%20few%20epochs.\n",
    "\n",
    "\n",
    "class VisionTransformerPretrained(L.LightningModule): \n",
    "    '''wrapper for the pretrained vision transformers'''\n",
    "\n",
    "    def __init__(self, model = \"google/vit-base-patch16-224\", num_classes = 15, learning_rate = 1e-4):\n",
    "\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate \n",
    "        self.num_classes = num_classes\n",
    "        backbone = ViTForImageClassification.from_pretrained(model, \n",
    "                                                             num_labels = num_classes, \n",
    "                                                             ignore_mismatched_sizes=True)\n",
    "        \n",
    "        self.backbone = backbone \n",
    "\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss() # adjusted for our task of multilabel \n",
    "\n",
    "        #metrics \n",
    "\n",
    "        self.acc = torchmetrics.Accuracy(\"multilabel\", num_labels=num_classes, threshold = 0.5)\n",
    "\n",
    "        self.f1 = torchmetrics.F1Score(task=\"multilabel\", num_labels=num_classes, average=None)  # Per-label F1\n",
    "        self.precision = torchmetrics.Precision(task=\"multilabel\", num_labels=num_classes, average=None)\n",
    "        self.recall = torchmetrics.Recall(task=\"multilabel\", num_labels=num_classes, average=None)\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multilabel\", num_labels=num_classes, average=None)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x): \n",
    "        return self.backbone(x).logits\n",
    "    \n",
    "    def step(self, batch, stage = \"train\"):\n",
    "        '''Any step proccesses to return loss and predictions'''\n",
    "\n",
    "        x, y = batch \n",
    "\n",
    "        logits = self.forward(x)\n",
    "        y_hat = (torch.sigmoid(logits)>0.5).float() # we need to \n",
    "\n",
    "        loss = self.loss_fn(logits, y.float())\n",
    "        acc = self.acc(y_hat, y)\n",
    "\n",
    "        return loss, acc, y_hat, y\n",
    "    \n",
    "    def training_step(self, batch, batch_idx): \n",
    "        loss, acc, y_hat, y = self.step(batch)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx): \n",
    "        loss, acc, y_hat, y = self.step(batch)\n",
    "\n",
    "        self.log(\"valid_acc\", acc, on_epoch = True, on_step = False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr = 1e-4)\n",
    "        return optimizer \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuggingFaceCXR(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset wrapper for Hugging Face datasets.\n",
    "    Converts dataset samples into a PyTorch-compatible format.\n",
    "    \"\"\"\n",
    "    def __init__(self, hf_dataset, image_size, num_classes=15, transform=None):\n",
    "        self.dataset = hf_dataset.with_format(\"torch\")  # Ensure dataset is in torch format\n",
    "        self.image_size = image_size\n",
    "        self.num_classes = num_classes\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "\n",
    "        # Load image\n",
    "        image = item[\"image\"]  # Ensure this matches your dataset keys\n",
    "\n",
    "        # Resize image\n",
    "        image = F.interpolate(image.unsqueeze(0), size = self.image_size, mode = \"bilinear\").squeeze(0)\n",
    "\n",
    "        # Handle 4-channel (RGBA) images: Keep only RGB\n",
    "        if image.shape[0] == 4:\n",
    "            image = image[:3, :, :]\n",
    "\n",
    "        # Handle Grayscale (1-channel) images: Convert to 3-channel\n",
    "        if image.shape[0] == 1:\n",
    "            image = image.repeat(3, 1, 1)\n",
    "\n",
    "        # Normalize pixel values to [0,1]\n",
    "        image = image / 255.0\n",
    "\n",
    "        # Convert labels to one-hot encoding\n",
    "        labels = item[\"labels\"]\n",
    "        one_hot = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        one_hot[labels] = 1  # Set corresponding indices to 1\n",
    "\n",
    "        # Apply optional transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import lightning as L\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "class nih_cxr_datamodule(L.LightningDataModule):\n",
    "    '''Lightning data module for the cxr dataset'''\n",
    "\n",
    "    def __init__(self, batch_size, data_root=\"alkzar90/NIH-Chest-X-ray-dataset\"): \n",
    "        super().__init__()\n",
    "        self.data_root = data_root\n",
    "        self.batch_size = batch_size \n",
    "        self.num_classes = 15\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        '''set up the dataset, train/valid/test all at once'''\n",
    "\n",
    "        transforms = v2.Compose([v2.ToImage(),\n",
    "                                 v2.Resize(size=(224,224), interpolation=2),\n",
    "                                 v2.Grayscale(num_output_channels=3), # need to ensure 3 channel grayscale for vit \n",
    "                                 v2.ToDtype(torch.float32, scale=True),\n",
    "                                 v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "                                ])\n",
    "        \n",
    "        ds_train = load_dataset(self.data_root, 'image-classification', split = \"train[:5000]\")\n",
    "\n",
    "        train_valid_split = ds_train.train_test_split(test_size = 0.2)\n",
    "\n",
    "        ds_train = train_valid_split['train']\n",
    "        ds_valid = train_valid_split['test']\n",
    "\n",
    " \n",
    "        ds_test = load_dataset(self.data_root, 'image-classification', split = \"test[:2000]\") \n",
    "\n",
    "        self.train_data = HuggingFaceCXR(ds_train, image_size = (224, 224), transform = transforms)\n",
    "        self.valid_data = HuggingFaceCXR(ds_valid, image_size = (224, 224), transform = transforms)\n",
    "        self.test_data = HuggingFaceCXR(ds_test, image_size = (224, 224), transform = transforms)\n",
    "\n",
    "\n",
    "    def train_dataloader(self): \n",
    "        return DataLoader(self.train_data, batch_size = self.batch_size, shuffle = True)\n",
    "    \n",
    "    def valid_dataloader(self): \n",
    "        return DataLoader(dataset = self.valid_data, batch_size = self.batch_size, shuffle = False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size = self.batch_size, shuffle = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def multi_label_evaluation(model, test_dataloader, test_dataset, logger): \n",
    "    model.eval()\n",
    "\n",
    "    all_true_labels = []\n",
    "    all_pred_logits = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc = \"Collecting logits\"): \n",
    "            x, y = batch \n",
    "            logits = model(x)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_true_labels.append(y.cpu().numpy())\n",
    "            all_pred_logits.append(probs) # store these so we can assess different thresholds quickly \n",
    "\n",
    "    all_true_labels = np.vstack(all_true_labels)\n",
    "    all_pred_logits = np.vstack(all_pred_logits)\n",
    "\n",
    "    label_list = test_dataset.features['labels'].feature.names\n",
    "\n",
    "    # now we try and find our best threshold before classificaiton report at that threshold \n",
    "    thresholds_to_test = np.linspace(0, 1, 10)\n",
    "    f1_micro_list = []\n",
    "\n",
    "    for value in thresholds_to_test:\n",
    "        predictions = (all_pred_logits >= value).astype(int)\n",
    "        report = classification_report(all_true_labels, predictions, target_names = label_list, output_dict = True)\n",
    "        micro_f1_average = report['micro avg']['f1-score']\n",
    "        f1_micro_list.append({\"Threshold\": value, \"Micro-F1\": micro_f1_average})\n",
    "\n",
    "    # save micro f1 scores \n",
    "    log_dir = logger.log_dir\n",
    "\n",
    "    os.makedirs(log_dir, exist_ok = True)\n",
    "    f1_micro_path = os.path.join(log_dir, \"f1_micro_average.csv\")\n",
    "    f1_micro_average_df = pd.DataFrame(f1_micro_list)\n",
    "    f1_micro_average_df.to_csv(f1_micro_path, index = False)\n",
    "   \n",
    "    # now select the threshold that gave the highest micro average \n",
    "\n",
    "    best_threshold = f1_micro_average_df.loc[f1_micro_average_df[\"Micro-F1\"].idxmax(), \"Threshold\"]\n",
    "\n",
    "    # calculate final labels based on best threshold \n",
    "\n",
    "    all_pred_labels = (all_pred_logits >= best_threshold).astype(int)\n",
    "    \n",
    "    report_path = os.path.join(log_dir, f\"test_multi_metrics_{best_threshold:.4f}.csv\")\n",
    "    final_report = classification_report(all_true_labels, all_pred_labels, target_names=label_list, zero_division=0, output_dict = True)\n",
    "    pd.DataFrame(final_report).to_csv(report_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def main(args): \n",
    "    L.seed_everything(42)\n",
    "\n",
    "    # set up data \n",
    "    datamodule = nih_cxr_datamodule(batch_size=8)\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup()\n",
    "\n",
    "    train_dataloader = datamodule.train_dataloader()\n",
    "    valid_dataloader = datamodule.valid_dataloader()\n",
    "    test_dataloader = datamodule.test_dataloader()\n",
    "\n",
    "    # setup model \n",
    "    model = VisionTransformerPretrained('google/vit-base-patch16-224', datamodule.num_classes, learning_rate= 1e-4)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor = 'valid_acc', patience = 6, mode = 'max')\n",
    "\n",
    "    logger = CSVLogger(\"tensorboard_logs\", name = 'nih_cxr_pretrained_vit')\n",
    "\n",
    "    #train \n",
    "    trainer = L.Trainer(devices = 1, max_epochs = 10, callbacks = [early_stopping], logger =logger)\n",
    "    trainer.fit(model = model, train_dataloaders=train_dataloader, val_dataloaders = valid_dataloader)\n",
    "\n",
    "    # evaluate on the test set \n",
    "    \n",
    "    # we want to set our threshold based on micro average due to class imbalance - use micro average f1 score \n",
    "\n",
    "    multi_label_evaluation(model, test_dataloader = test_dataloader, \n",
    "                           test_dataset = ds_test, logger = logger)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([15]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([15, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m args = \u001b[33m\"\u001b[39m\u001b[33marg\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m run = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m#train \u001b[39;00m\n\u001b[32m     26\u001b[39m trainer = L.Trainer(devices = \u001b[32m1\u001b[39m, max_epochs = \u001b[32m10\u001b[39m, callbacks = [early_stopping], logger =logger)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# evaluate on the test set \u001b[39;00m\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# we want to set our threshold based on micro average due to class imbalance - use micro average f1 score \u001b[39;00m\n\u001b[32m     33\u001b[39m multi_label_evaluation(model, test_dataloader = test_dataloader, \n\u001b[32m     34\u001b[39m                        test_dataset = ds_test, logger = logger)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:539\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    538\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:47\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     50\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:575\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    569\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    570\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    571\u001b[39m     ckpt_path,\n\u001b[32m    572\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    573\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    574\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    578\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:958\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28mself\u001b[39m._logger_connector.reset_metrics()\n\u001b[32m    957\u001b[39m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m958\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.fn == TrainerFn.FITTING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:155\u001b[39m, in \u001b[36mStrategy.setup\u001b[39m\u001b[34m(self, trainer)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# let the precision plugin convert the module here so that this strategy hook can decide the order\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# of operations\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.precision_plugin.convert_module(\u001b[38;5;28mself\u001b[39m.model)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m._setup_model(\u001b[38;5;28mself\u001b[39m.model)\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.state.fn == TrainerFn.FITTING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/lightning/pytorch/strategies/single_device.py:79\u001b[39m, in \u001b[36mSingleDeviceStrategy.model_to_device\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mself.model must be set before self.model.to()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/lightning/fabric/utilities/device_dtype_mixin.py:55\u001b[39m, in \u001b[36m_DeviceDtypeModuleMixin.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m device, dtype = torch._C._nn._parse_to(*args, **kwargs)[:\u001b[32m2\u001b[39m]\n\u001b[32m     54\u001b[39m _update_properties(\u001b[38;5;28mself\u001b[39m, device=device, dtype=dtype)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1343\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1340\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1341\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[31m[... skipping similar frames: Module._apply at line 903 (2 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    927\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    928\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    931\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    933\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pytorch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1329\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1322\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1323\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1324\u001b[39m             device,\n\u001b[32m   1325\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1326\u001b[39m             non_blocking,\n\u001b[32m   1327\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1328\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1335\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "args = \"arg\"\n",
    "run = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
