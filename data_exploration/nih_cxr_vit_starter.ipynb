{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverfox/venvs/ml_venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "import torch \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from tqdm import trange, tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import os \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#If you haven't downloaded already, this takes aroun  40GB and around half an hour to download all the data (note that we split here)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# it will be cached on your system, so you access it in the future by running this code (rather than opening the files per se)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# once you've downloaded, hugging face automatically checks to see if you've already downloaded so subsequent loads are quick \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# we use just a small portion here to get our code working \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# hugging face has already split in to train and test so we can use train here and make a validation subset in our custom dataset class \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m ds_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malkzar90/NIH-Chest-X-ray-dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage-classification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# we hold back our test data to be used purely for testing, not in the context of our training loop \u001b[39;00m\n\u001b[1;32m     10\u001b[0m ds_test \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malkzar90/NIH-Chest-X-ray-dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage-classification\u001b[39m\u001b[38;5;124m'\u001b[39m, split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest[:500]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/load.py:2154\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance\u001b[38;5;241m.\u001b[39mas_streaming_dataset(split\u001b[38;5;241m=\u001b[39msplit)\n\u001b[1;32m   2153\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 2154\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2163\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2164\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   2165\u001b[0m )\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/builder.py:924\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    923\u001b[0m     prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m--> 924\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/builder.py:1648\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_splits_kwargs):\n\u001b[0;32m-> 1648\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_duplicate_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBASIC_CHECKS\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_CHECKS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_splits_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/builder.py:978\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m SplitDict(dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name)\n\u001b[1;32m    977\u001b[0m split_generators_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m--> 978\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msplit_generators_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# Checksums verification\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS \u001b[38;5;129;01mand\u001b[39;00m dl_manager\u001b[38;5;241m.\u001b[39mrecord_checksums:\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/alkzar90--NIH-Chest-X-ray-dataset/718c2bf39ec92a3b8a64026367a3b8ac16f9ae8dc1f8689c87485241c8ca8616/NIH-Chest-X-ray-dataset.py:179\u001b[0m, in \u001b[0;36mChestXray14._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    176\u001b[0m test_files \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Download batches\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_URLS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_urls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Iterate trought image folder and check if they belong to\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# the trainset or testset\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m data_files:\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/download/download_manager.py:326\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload_and_extract\u001b[39m(\u001b[38;5;28mself\u001b[39m, url_or_urls):\n\u001b[1;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download and extract given `url_or_urls`.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    Is roughly equivalent to:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m        extracted_path(s): `str`, extracted paths of given URL(s).\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/download/download_manager.py:159\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    157\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m stack_multiprocessing_download_progress_bars():\n\u001b[0;32m--> 159\u001b[0m     downloaded_path_or_paths \u001b[38;5;241m=\u001b[39m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDownloading data files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m duration \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    169\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;241m.\u001b[39mtotal_seconds()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/utils/py_utils.py:511\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    509\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_proc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m%\u001b[39m num_proc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    510\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[0;32m--> 511\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    512\u001b[0m     _single_map_nested((function, obj, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m hf_tqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    514\u001b[0m ]\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[1;32m    516\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/utils/py_utils.py:512\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    509\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_proc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m%\u001b[39m num_proc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    510\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[1;32m    511\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 512\u001b[0m     \u001b[43m_single_map_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m hf_tqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    514\u001b[0m ]\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[1;32m    516\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/utils/py_utils.py:380\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    375\u001b[0m     batched\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[1;32m    379\u001b[0m ):\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m function(batch)]\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mget_verbosity() \u001b[38;5;241m<\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/utils/py_utils.py:380\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m function(data_struct)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    375\u001b[0m     batched\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types)\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (\u001b[38;5;28mdict\u001b[39m, types)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m data_struct)\n\u001b[1;32m    379\u001b[0m ):\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iter_batched(data_struct, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mget_verbosity() \u001b[38;5;241m<\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARNING:\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/download/download_manager.py:219\u001b[0m, in \u001b[0;36mDownloadManager._download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    207\u001b[0m         download_func,\n\u001b[1;32m    208\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m         tqdm_class\u001b[38;5;241m=\u001b[39mtqdm,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_single(url_or_filename, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[1;32m    222\u001b[0m     ]\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/download/download_manager.py:220\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m thread_map(\n\u001b[1;32m    207\u001b[0m         download_func,\n\u001b[1;32m    208\u001b[0m         url_or_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m         tqdm_class\u001b[38;5;241m=\u001b[39mtqdm,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 220\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m url_or_filename \u001b[38;5;129;01min\u001b[39;00m url_or_filenames\n\u001b[1;32m    222\u001b[0m     ]\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/download/download_manager.py:229\u001b[0m, in \u001b[0;36mDownloadManager._download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_relative_path(url_or_filename):\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# append the relative path to the base_path\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     url_or_filename \u001b[38;5;241m=\u001b[39m url_or_path_join(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_path, url_or_filename)\n\u001b[0;32m--> 229\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m out \u001b[38;5;241m=\u001b[39m tracked_str(out)\n\u001b[1;32m    231\u001b[0m out\u001b[38;5;241m.\u001b[39mset_origin(url_or_filename)\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/datasets/utils/file_utils.py:182\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m huggingface_hub\u001b[38;5;241m.\u001b[39mHfFileSystem(\n\u001b[1;32m    179\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mHF_ENDPOINT, token\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mtoken\n\u001b[1;32m    180\u001b[0m )\u001b[38;5;241m.\u001b[39mresolve_path(url_or_filename)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mhuggingface_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHfApi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHF_ENDPOINT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_datasets_user_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_in_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    197\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRepositoryNotFoundError,\n\u001b[1;32m    198\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mEntryNotFoundError,\n\u001b[1;32m    199\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mRevisionNotFoundError,\n\u001b[1;32m    200\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mGatedRepoError,\n\u001b[1;32m    201\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/huggingface_hub/hf_api.py:5248\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   5244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5245\u001b[0m     \u001b[38;5;66;03m# Cannot do `token = token or self.token` as token can be `False`.\u001b[39;00m\n\u001b[1;32m   5246\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m-> 5248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5251\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5260\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5264\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5269\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/huggingface_hub/file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    844\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    859\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    860\u001b[0m     )\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1011\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1009\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1011\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1022\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/huggingface_hub/file_download.py:1547\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1544\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1545\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1547\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1556\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1557\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m~/venvs/ml_venv/lib/python3.8/site-packages/huggingface_hub/file_download.py:457\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n\u001b[0;32m--> 457\u001b[0m     \u001b[43mtemp_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     new_resume_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# Some data has been downloaded from the server so we reset the number of retries.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#If you haven't downloaded already, this takes aroun  40GB and around half an hour to download all the data (note that we split here)\n",
    "# it will be cached on your system, so you access it in the future by running this code (rather than opening the files per se)\n",
    "# once you've downloaded, hugging face automatically checks to see if you've already downloaded so subsequent loads are quick \n",
    "\n",
    "# we use just a small portion here to get our code working \n",
    "# hugging face has already split in to train and test so we can use train here and make a validation subset in our custom dataset class \n",
    "ds_train = load_dataset(\"alkzar90/NIH-Chest-X-ray-dataset\", 'image-classification', split = \"train\") \n",
    "\n",
    "# we hold back our test data to be used purely for testing, not in the context of our training loop \n",
    "ds_test = load_dataset(\"alkzar90/NIH-Chest-X-ray-dataset\", 'image-classification', split = \"test[:500]\") \n",
    "\n",
    "# you can view a single image to check things have worked \n",
    "ds_train[300]['image']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 46863.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(4)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(image_tensor, patch_size = 4):\n",
    "    bs, c, h, w = image_tensor.size()\n",
    "\n",
    "    # define teh unfold layer with appropriate parameters \n",
    "\n",
    "    unfold = torch.nn.Unfold(kernel_size = patch_size, stride = patch_size)\n",
    "\n",
    "    unfolded = unfold(image_tensor)\n",
    "\n",
    "    # reshape the unfolded tensor to match the desired output shape \n",
    "    # output shaep BS x L x C x 8 x8 where L is the number of patches in each dimension \n",
    "    # fo reach dimension, number of patches = (original dimension size) //patch_size \n",
    "\n",
    "    unfolded = unfolded.transpose(1, 2).reshape(bs, -1, c * patch_size * patch_size)\n",
    "\n",
    "    return unfolded\n",
    "\n",
    "\n",
    "# we have a hugging face dataset, so we now define a custom dataset class which processes this, ensures our labels are one hot encoded etc. \n",
    "\n",
    "class MultiLabelDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Initialize with a Hugging Face dataset that's already formatted as torch tensors. \n",
    "    Will convert to tensors if plain hugging face dataset. \n",
    "    Will handle the multi label nature of our data through one hot encoding \n",
    "    \n",
    "    Args:\n",
    "        hf_dataset: A Hugging Face dataset with 'image' and 'labels' columns\n",
    "    \"\"\"\n",
    "      \n",
    "    def __init__(self, hf_dataset, image_size):\n",
    "\n",
    "        self.x_train, self.x_val, self.y_train, self.y_val = None, None, None, None\n",
    "        self.mode = \"train\"\n",
    "\n",
    "        hf_dataset = hf_dataset.with_format(\"torch\")\n",
    "        print(hf_dataset.format)\n",
    "\n",
    "        self.processed_images = []\n",
    "        self.processed_labels = []\n",
    "\n",
    "        for sample in tqdm(hf_dataset, desc = \"processing images\", leave= True):\n",
    "            image = sample['image']\n",
    "\n",
    "            # we resize our image if specified \n",
    "            \n",
    "            image = F.interpolate(image.unsqueeze(0), size = image_size, mode = \"bilinear\").squeeze(0)\n",
    "\n",
    "\n",
    "            if image.shape[0] == 4:\n",
    "                image = torch.index_select(image, 0, torch.tensor([0]))\n",
    "\n",
    "            # normalize pixel values \n",
    "            image = image/255\n",
    "\n",
    "            if image.shape[0] == 1:\n",
    "                image = image.repeat(3, 1, 1) # for convolutional networks we need 3 channels, remove this line and line below if wanting 1024, 1024 shape \n",
    "\n",
    "            # image = image.permute(1, 2, 0) # channel dimension needs to be the last one, not first \n",
    "\n",
    "            labels = sample['labels']\n",
    "            one_hot = torch.zeros(15, dtype = torch.long)\n",
    "            one_hot[labels] = 1\n",
    "            self.processed_images.append(image)\n",
    "            self.processed_labels.append(one_hot)\n",
    "    \n",
    "    def train_validation_split(self):\n",
    "        \"\"\"\n",
    "        Takes our training data and produces a validation set from our training data\n",
    "        Ensures that we don't use our hugging face defined test set during the training process \n",
    "        Means that we will assess trained models on a totally separate test set to avoid overfitting on test set\n",
    "        Note that we use a subset of train as a validation set \n",
    "        \"\"\"\n",
    "        self.x_train, self.x_val, self.y_train, self.y_val = train_test_split(self.processed_images, self.processed_labels, test_size = 0.2,\n",
    "                                                                              random_state = 42)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Returns the length of our training or validation set depending on mode \"\"\"\n",
    "        if self.mode == \"train\":\n",
    "            return len(self.x_train)\n",
    "        elif self.mode == \"val\":\n",
    "            return len(self.x_val)\n",
    "        elif self.mode == \"test\":\n",
    "            return len(self.processed_images)\n",
    "    \n",
    "        \n",
    "\n",
    "    # note we are not doing lazy processing, so our data is processed when the dataset is instantiated. \n",
    "    # here we will return a train test split of our hugging face training data, unless we're using the test data in which case we return it all \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Gets items from either the training or validation set depending on mode\"\"\"\n",
    "        if self.mode == \"train\":\n",
    "            return {\"image\": self.x_train[idx], \"labels\": self.y_train[idx]}\n",
    "        elif self.mode == \"val\":\n",
    "            return {\"image\": self.x_val[idx], \"labels\": self.y_val[idx]}\n",
    "        elif self.mode == \"test\":\n",
    "            return {\"image\": self.processed_images[idx], \"labels\": self.processed_labels[idx]}\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# we create patches \n",
    "# we embed these patches by using encoder only transformer \n",
    "# then we pass them through an encoder only transformer \n",
    "# use a transformer - self attention mixes spatial regions of an image earlier on (rather than convolutions which takes time to get entire spatial field of image)\n",
    "# by treating every pixel as an embedding in a sequence, each spatial region can query all other spatial regions in image - gives context \n",
    "\n",
    "# neeed to start by writing a transformer block class with self attention \n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_size = 128, num_heads = 4):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "\n",
    "        # layer normalisation to normalize the input data \n",
    "        self.norm1 = nn.LayerNorm(hidden_size)\n",
    "\n",
    "\n",
    "        # multi head attention mechanism \n",
    "\n",
    "        self.multihead_attn = nn.MultiheadAttention(hidden_size, num_heads=num_heads, \n",
    "                                                    batch_first = True, dropout = 0.1)\n",
    "        \n",
    "        # another layer of normalisation \n",
    "\n",
    "        self.norm2 = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        # multi layer perceptron with a hidden layer and activation function \n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size *2), \n",
    "            nn.LayerNorm(hidden_size * 2),\n",
    "            nn.ELU(), \n",
    "            nn.Linear(hidden_size * 2, hidden_size))\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # apply the first layer of normalisation \n",
    "\n",
    "        norm_x = self.norm1(x)\n",
    "\n",
    "        # apply multi headed attention and add the input (residual connection)\n",
    "\n",
    "        x = self.multihead_attn(norm_x, norm_x, norm_x)[0] + x\n",
    "\n",
    "        # apply second layer of normalisation \n",
    "\n",
    "        norm_x = self.norm2(x)\n",
    "\n",
    "        # pass through the mlp and add the input (Residual connection)\n",
    "\n",
    "        x = self.mlp(norm_x) + x\n",
    "\n",
    "        return x \n",
    "        \n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, image_size, channels_in, patch_size, hidden_size,\n",
    "                 num_layers, num_heads = 8):\n",
    "        super(ViT, self).__init__()\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        # fully connected layer to project input patches to the hidden size dimension \n",
    "\n",
    "        self.fc_in = nn.Linear(channels_in * patch_size * patch_size, hidden_size) # this is causing a problem atm \n",
    "\n",
    "        # create list of transformer blocks \n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(hidden_size, num_heads) for _ in range(num_layers)])\n",
    "        \n",
    "        # fully connected output layer to map to the number of classes \n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_size, 15)\n",
    "\n",
    "        # parameter for the output token \n",
    "\n",
    "        self.out_vec = nn.Parameter(torch.zeros(1, 1, hidden_size))\n",
    "\n",
    "        # positional embeddings to retain positional information of patches \n",
    "\n",
    "        seq_length = (image_size //patch_size) **2\n",
    "        self.pos_embedding = nn.Parameter(torch.empty(1, seq_length, hidden_size).normal_(std = 0.001))\n",
    "\n",
    "    def forward(self, image):\n",
    "\n",
    "        bs = image.shape[0]\n",
    "\n",
    "        # extract patches from the image and flatten them \n",
    "\n",
    "        patch_seq = extract_patches(image, patch_size = self.patch_size)\n",
    "\n",
    "        \n",
    "\n",
    "        # project patches to the hidden size dimension \n",
    "\n",
    "        patch_emb = self.fc_in(patch_seq)\n",
    "\n",
    "\n",
    "        # add positional embeddings to the patch embeddings \n",
    "\n",
    "        patch_emb = patch_emb + self.pos_embedding\n",
    "\n",
    "        # concatenate the output token to the patch embeddings \n",
    "\n",
    "        embs = torch.cat((self.out_vec.expand(bs, 1, -1), patch_emb), 1)\n",
    "\n",
    "        # pass embeddings through each transformer block \n",
    "\n",
    "        for block in self.blocks: \n",
    "            embs = block(embs)\n",
    "\n",
    "        return self.fc_out(embs[:, 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'torch', 'format_kwargs': {}, 'columns': ['image', 'labels'], 'output_all_columns': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing images: 100%|██████████| 500/500 [00:04<00:00, 122.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of training data is: 400\n",
      " the size of validation data is: 100\n",
      "{'type': 'torch', 'format_kwargs': {}, 'columns': ['image', 'labels'], 'output_all_columns': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing images: 100%|██████████| 500/500 [00:03<00:00, 129.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# now we can produce our train and validation dataloaders which will be used in training later\n",
    "training_dataset_class = MultiLabelDataset(ds_train, image_size = (128, 128)) # make sure to have the channel dimension\n",
    "training_dataset_class.train_validation_split()\n",
    "\n",
    "# set dataset class mode to train to generate a training split \n",
    "training_dataset_class.mode = \"train\"\n",
    "print(f\"the size of training data is: {len(training_dataset_class)}\")\n",
    "train_dataloader = DataLoader(training_dataset_class, batch_size = 4, shuffle = True)\n",
    "\n",
    "# set dataset class mode to val to generate a validation split \n",
    "\n",
    "training_dataset_class.mode = \"val\"\n",
    "print(f\" the size of validation data is: {len(training_dataset_class)}\")\n",
    "val_dataloader = DataLoader(training_dataset_class, batch_size = 4, shuffle = True)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset_class = MultiLabelDataset(ds_test, image_size = (128, 128))\n",
    "test_dataset_class.mode = \"test\"\n",
    "test_dataloader = DataLoader(test_dataset_class, batch_size = 4, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MultiLabelDataset at 0x3211c8850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'torch', 'format_kwargs': {}, 'columns': ['image', 'labels'], 'output_all_columns': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing images: 100%|██████████| 500/500 [00:16<00:00, 29.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of training data is: 400\n",
      " the size of validation data is: 100\n",
      "{'type': 'torch', 'format_kwargs': {}, 'columns': ['image', 'labels'], 'output_all_columns': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing images: 100%|██████████| 500/500 [00:16<00:00, 29.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model works with your data\n",
      "Output shape: torch.Size([4, 15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "training:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "training:   4%|▍         | 1/25 [00:04<01:40,  4.18s/it]\u001b[A\n",
      "training:   8%|▊         | 2/25 [00:08<01:35,  4.17s/it]\u001b[A\n",
      "training:  12%|█▏        | 3/25 [00:12<01:31,  4.16s/it]\u001b[A\n",
      "training:  16%|█▌        | 4/25 [00:16<01:27,  4.15s/it]\u001b[A\n",
      "training:  20%|██        | 5/25 [00:20<01:22,  4.14s/it]\u001b[A\n",
      "training:  24%|██▍       | 6/25 [00:24<01:18,  4.14s/it]\u001b[A\n",
      "training:  28%|██▊       | 7/25 [00:29<01:14,  4.14s/it]\u001b[A\n",
      "training:  32%|███▏      | 8/25 [00:33<01:10,  4.13s/it]\u001b[A\n",
      "training:  36%|███▌      | 9/25 [00:37<01:06,  4.13s/it]\u001b[A\n",
      "training:  40%|████      | 10/25 [00:41<01:01,  4.13s/it]\u001b[A\n",
      "training:  44%|████▍     | 11/25 [00:45<00:57,  4.13s/it]\u001b[A\n",
      "training:  48%|████▊     | 12/25 [00:49<00:53,  4.13s/it]\u001b[A\n",
      "training:  52%|█████▏    | 13/25 [00:53<00:49,  4.13s/it]\u001b[A\n",
      "training:  56%|█████▌    | 14/25 [00:57<00:45,  4.13s/it]\u001b[A\n",
      "training:  60%|██████    | 15/25 [01:02<00:41,  4.14s/it]\u001b[A\n",
      "training:  64%|██████▍   | 16/25 [01:06<00:37,  4.14s/it]\u001b[A\n",
      "training:  68%|██████▊   | 17/25 [01:10<00:33,  4.14s/it]\u001b[A\n",
      "training:  72%|███████▏  | 18/25 [01:14<00:28,  4.14s/it]\u001b[A\n",
      "training:  76%|███████▌  | 19/25 [01:18<00:24,  4.14s/it]\u001b[A\n",
      "training:  80%|████████  | 20/25 [01:22<00:20,  4.13s/it]\u001b[A\n",
      "training:  84%|████████▍ | 21/25 [01:26<00:16,  4.13s/it]\u001b[A\n",
      "training:  88%|████████▊ | 22/25 [01:31<00:12,  4.13s/it]\u001b[A\n",
      "training:  92%|█████████▏| 23/25 [01:35<00:08,  4.13s/it]\u001b[A\n",
      "training:  96%|█████████▌| 24/25 [01:39<00:04,  4.13s/it]\u001b[A\n",
      "training: 100%|██████████| 25/25 [01:43<00:00,  4.14s/it]\n",
      "\n",
      "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▍         | 1/25 [00:00<00:15,  1.50it/s]\u001b[A\n",
      "Evaluating:   8%|▊         | 2/25 [00:01<00:15,  1.50it/s]\u001b[A\n",
      "Evaluating:  12%|█▏        | 3/25 [00:02<00:14,  1.50it/s]\u001b[A\n",
      "Evaluating:  16%|█▌        | 4/25 [00:02<00:14,  1.49it/s]\u001b[A\n",
      "Evaluating:  20%|██        | 5/25 [00:03<00:13,  1.50it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 6/25 [00:04<00:12,  1.50it/s]\u001b[A\n",
      "Evaluating:  28%|██▊       | 7/25 [00:04<00:12,  1.49it/s]\u001b[A\n",
      "Evaluating:  32%|███▏      | 8/25 [00:05<00:11,  1.49it/s]\u001b[A\n",
      "Evaluating:  36%|███▌      | 9/25 [00:06<00:10,  1.49it/s]\u001b[A\n",
      "Evaluating:  40%|████      | 10/25 [00:06<00:10,  1.49it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 11/25 [00:07<00:09,  1.49it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 12/25 [00:08<00:08,  1.49it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 13/25 [00:08<00:08,  1.49it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 14/25 [00:09<00:07,  1.49it/s]\u001b[A\n",
      "Evaluating:  60%|██████    | 15/25 [00:10<00:06,  1.49it/s]\u001b[A\n",
      "Evaluating:  64%|██████▍   | 16/25 [00:10<00:06,  1.49it/s]\u001b[A\n",
      "Evaluating:  68%|██████▊   | 17/25 [00:11<00:05,  1.49it/s]\u001b[A\n",
      "Evaluating:  72%|███████▏  | 18/25 [00:12<00:04,  1.50it/s]\u001b[A\n",
      "Evaluating:  76%|███████▌  | 19/25 [00:12<00:04,  1.50it/s]\u001b[A\n",
      "Evaluating:  80%|████████  | 20/25 [00:13<00:03,  1.49it/s]\u001b[A\n",
      "Evaluating:  84%|████████▍ | 21/25 [00:14<00:02,  1.49it/s]\u001b[A\n",
      "Evaluating:  88%|████████▊ | 22/25 [00:14<00:02,  1.49it/s]\u001b[A\n",
      "Evaluating:  92%|█████████▏| 23/25 [00:15<00:01,  1.49it/s]\u001b[A\n",
      "Evaluating:  96%|█████████▌| 24/25 [00:16<00:00,  1.49it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 25/25 [00:16<00:00,  1.49it/s]\n",
      "\n",
      "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▍         | 1/25 [00:00<00:16,  1.50it/s]\u001b[A\n",
      "Evaluating:   8%|▊         | 2/25 [00:01<00:15,  1.50it/s]\u001b[A\n",
      "Evaluating:  12%|█▏        | 3/25 [00:02<00:14,  1.49it/s]\u001b[A\n",
      "Evaluating:  16%|█▌        | 4/25 [00:02<00:14,  1.49it/s]\u001b[A\n",
      "Evaluating:  20%|██        | 5/25 [00:03<00:13,  1.49it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 6/25 [00:04<00:12,  1.49it/s]\u001b[A\n",
      "Evaluating:  28%|██▊       | 7/25 [00:04<00:12,  1.49it/s]\u001b[A\n",
      "Evaluating:  32%|███▏      | 8/25 [00:05<00:11,  1.49it/s]\u001b[A\n",
      "Evaluating:  36%|███▌      | 9/25 [00:06<00:10,  1.50it/s]\u001b[A\n",
      "Evaluating:  40%|████      | 10/25 [00:06<00:10,  1.49it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 11/25 [00:07<00:09,  1.49it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 12/25 [00:08<00:08,  1.49it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 13/25 [00:08<00:08,  1.49it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 14/25 [00:09<00:07,  1.49it/s]\u001b[A\n",
      "Evaluating:  60%|██████    | 15/25 [00:10<00:06,  1.49it/s]\u001b[A\n",
      "Evaluating:  64%|██████▍   | 16/25 [00:10<00:06,  1.49it/s]\u001b[A\n",
      "Evaluating:  68%|██████▊   | 17/25 [00:11<00:05,  1.49it/s]\u001b[A\n",
      "Evaluating:  72%|███████▏  | 18/25 [00:12<00:04,  1.49it/s]\u001b[A\n",
      "Evaluating:  76%|███████▌  | 19/25 [00:12<00:04,  1.49it/s]\u001b[A\n",
      "Evaluating:  80%|████████  | 20/25 [00:13<00:03,  1.49it/s]\u001b[A\n",
      "Evaluating:  84%|████████▍ | 21/25 [00:14<00:02,  1.49it/s]\u001b[A\n",
      "Evaluating:  88%|████████▊ | 22/25 [00:14<00:02,  1.49it/s]\u001b[A\n",
      "Evaluating:  92%|█████████▏| 23/25 [00:15<00:01,  1.49it/s]\u001b[A\n",
      "Evaluating:  96%|█████████▌| 24/25 [00:16<00:00,  1.50it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 25/25 [00:16<00:00,  1.49it/s]\n",
      "epoch: 100%|██████████| 1/1 [02:16<00:00, 136.93s/it, Accuracy: Train 0.00%, Val 0.00%]\n",
      "/var/tmp/pbs.851483.pbs/ipykernel_3714866/2017306249.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"../trained_models/best_model.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 125/125 [01:23<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrices saved in: ../results/plots/confusion_matrices\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# create model and view the output \n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "patch_size = 4\n",
    "\n",
    "train_images = batch['image']\n",
    "train_labels = batch['labels']\n",
    "\n",
    "# set channels_in to the number of channels of the dataset images (in our case we have 3 channels)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ViT(image_size = train_images.shape[2], \n",
    "            channels_in = train_images.shape[1], \n",
    "            patch_size = patch_size, \n",
    "            hidden_size = 128, \n",
    "            num_layers = 8, \n",
    "            num_heads = 8).to(device)\n",
    "\n",
    "# pass an image through the network to check it works\n",
    "\n",
    "try:\n",
    "    out = model(train_images.to(device))\n",
    "    print(\"The model works with your data\")\n",
    "    print(\"Output shape:\", out.shape)  # Optional: Print the output shape\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "\n",
    "\n",
    "# set up the optimizer \n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, \n",
    "                                                    T_max = num_epochs, \n",
    "                                                    eta_min = 0)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss() # note that we use this as we have multiple labels \n",
    "\n",
    "# define the training process ---------------------------\n",
    "\n",
    "def train(model, optimizer, loader, device, loss_fn, loss_logger):\n",
    "\n",
    "    # set network in train mode\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for i, batch in enumerate(tqdm(loader, leave = True, desc = \"training\")):\n",
    "        # forward pass of image through network and get output \n",
    "\n",
    "        x = batch['image']\n",
    "        y = batch['labels']\n",
    "\n",
    "        fx = model(x.to(device))\n",
    "\n",
    "        # calculate loss using loss function \n",
    "\n",
    "        loss = loss_fn(fx, y.float().to(device)) # this requires correct float \n",
    "\n",
    "        # zero gradients \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # back propagate\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # single optimisation step \n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0  # Compute epoch loss\n",
    "    loss_logger.append(avg_loss)  # Store epoch loss\n",
    "\n",
    "    return model, optimizer, loss_logger\n",
    "\n",
    "\n",
    "# define the testing process\n",
    "\n",
    "def exact_match_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the exact match accuracy.\n",
    "    A sample is counted as correct only if all labels match exactly.\n",
    "    \"\"\"\n",
    "    return (y_true == y_pred).all(dim=1).float().mean().item()\n",
    "\n",
    "# This function should perform a single evaluation epoch, it WILL NOT be used to train our model\n",
    "def evaluate(model, device, loader):\n",
    "    \n",
    "    # Initialise counter\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    # Set network in evaluation mode\n",
    "    # Layers like Dropout will be disabled\n",
    "    # Layers like Batchnorm will stop calculating running mean and standard deviation\n",
    "    # and use current stored values (More on these layer types soon!)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        epoch_predicted_labels = []\n",
    "        epoch_ground_truth_labels = []\n",
    "\n",
    "        for i, batch in enumerate(tqdm(loader, leave=True, desc=\"Evaluating\")):\n",
    "\n",
    "                x = batch['image']\n",
    "                y = batch['labels']\n",
    "                # Forward pass of image through network\n",
    "                fx = model(x.to(device))\n",
    "                \n",
    "                preds = (torch.sigmoid(fx) > 0.5).float()\n",
    "                # Log the cumulative sum of the acc\n",
    "\n",
    "                epoch_predicted_labels.append(preds.cpu().numpy())\n",
    "                epoch_ground_truth_labels.append(y.cpu().numpy())\n",
    "\n",
    "        # Concatenate all batches\n",
    "        y_true_np = np.vstack(epoch_ground_truth_labels)\n",
    "        y_pred_np = np.vstack(epoch_predicted_labels)\n",
    "\n",
    "        exact_acc = accuracy_score(y_true_np, y_pred_np)\n",
    "                                             \n",
    "                    \n",
    "\n",
    "\n",
    "            \n",
    "    # Return the accuracy from the epoch     \n",
    "    return exact_acc\n",
    "\n",
    "\n",
    "\n",
    "# now the training process \n",
    "\n",
    "training_loss_logger = []\n",
    "validation_acc_logger = []\n",
    "training_acc_logger = []\n",
    "best_val_accuracy = 0\n",
    "best_model_path = \"../trained_models/best_model.pth\"  # Path to save the best model\n",
    "\n",
    "\n",
    "\n",
    "# this implements training loop \n",
    "\n",
    "pbar = trange(0, num_epochs, leave= True, desc = \"epoch\")\n",
    "\n",
    "for epoch in pbar: \n",
    "    valid_acc = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    model, optimizer, training_loss_logger = train(model = model, \n",
    "                                                   optimizer = optimizer, \n",
    "                                                   loader = train_dataloader,\n",
    "                                                   device = device, \n",
    "                                                   loss_fn = loss_fn, \n",
    "                                                   loss_logger = training_loss_logger\n",
    "                                                   )\n",
    "    \n",
    "    # call evaluate function and pass dataloader for both validaiton and training \n",
    "\n",
    "    train_acc = evaluate(model = model, device = device, loader = train_dataloader)\n",
    "    valid_acc = evaluate(model = model, device = device, loader = val_dataloader) # note we are using exact match accuracy \n",
    "\n",
    "    \n",
    "\n",
    "    # log the train and validation accuracies \n",
    "\n",
    "    validation_acc_logger.append(valid_acc)\n",
    "    training_acc_logger.append(train_acc)\n",
    "\n",
    "    if valid_acc > best_val_accuracy:\n",
    "        best_val_accuracy = valid_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"New best model saved with validation accuracy: {valid_acc:.4f}\")\n",
    "\n",
    "    # reduce the learning rate \n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    pbar.set_postfix_str(\"Accuracy: Train %.2f%%, Val %.2f%%\" % (train_acc * 100, valid_acc * 100))\n",
    "\n",
    "print(\"Training complete\")\n",
    "\n",
    "dict = {\"training_loss\": training_loss_logger, \n",
    "        \"validation_accuracy\": validation_acc_logger, \n",
    "        \"training_accuracy\": training_acc_logger}\n",
    "\n",
    "training_logs = pd.DataFrame(dict)\n",
    "training_logs.to_csv(\"../results/training_logs.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get class label mapping from Hugging Face dataset\n",
    "label_list = ds_test.features['labels'].feature.names  # List of string labels\n",
    "num_classes = len(label_list)\n",
    "\n",
    "# Initialize lists to store all predictions and labels\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "\n",
    "model = ViT(image_size = train_images.shape[2], \n",
    "            channels_in = train_images.shape[1], \n",
    "            patch_size = patch_size, \n",
    "            hidden_size = 128, \n",
    "            num_layers = 8, \n",
    "            num_heads = 8).to(device)\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load(\"../trained_models/best_model.pth\", map_location=device))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Loop over all batches in the dataloader\n",
    "for batch in tqdm(test_dataloader, leave= True, desc=\"Processing Batches\"):\n",
    "    \n",
    "    batch_image = batch['image']\n",
    "    batch_labels = batch['labels']  # True labels\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fx = model(batch_image.to(device))  # Forward pass\n",
    "        pred = (torch.sigmoid(fx) > 0.5).float()  # Convert logits to binary labels\n",
    "\n",
    "    # Store batch labels and predictions\n",
    "    all_true_labels.append(batch_labels.cpu().numpy())  # Convert to NumPy and store\n",
    "    all_pred_labels.append(pred.cpu().int().numpy())\n",
    "\n",
    "# Convert lists to full NumPy arrays\n",
    "all_true_labels = np.vstack(all_true_labels)  # Shape: (num_samples, num_classes)\n",
    "all_pred_labels = np.vstack(all_pred_labels)  # Shape: (num_samples, num_classes)\n",
    "\n",
    "\n",
    "# Compute multi-label confusion matrix\n",
    "multi_cm = multilabel_confusion_matrix(all_true_labels, all_pred_labels)\n",
    "\n",
    "# Function to plot confusion matrices with labels\n",
    "def plot_and_save_confusion_matrix(cm, class_name, save_path):\n",
    "    \"\"\"\n",
    "    Plots and saves a single confusion matrix with labels.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(f\"Confusion Matrix for {class_name}\")\n",
    "\n",
    "    # Save the figure\n",
    "    file_name = f\"{save_path}/confusion_matrix_{class_name}.png\"\n",
    "    plt.savefig(file_name, bbox_inches='tight', dpi=300)\n",
    "    plt.close()  # Close the figure to free memory\n",
    "\n",
    "# Define the directory where to save the files\n",
    "save_directory = \"../results/plots/confusion_matrices\"\n",
    "\n",
    "# Ensure the directory exists\n",
    "\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# Plot and save each confusion matrix with its class name\n",
    "for label, cm in zip(label_list, multi_cm):\n",
    "    plot_and_save_confusion_matrix(cm, label, save_directory)\n",
    "\n",
    "print(f\"Confusion matrices saved in: {save_directory}\")\n",
    "\n",
    "\n",
    "\n",
    "# Compute multi-label confusion matrix\n",
    "multi_cm = multilabel_confusion_matrix(all_true_labels, all_pred_labels)\n",
    "\n",
    "# Initialize lists to store per-class metrics\n",
    "class_names = label_list  # Class labels from dataset\n",
    "precision_list, recall_list, f1_list, accuracy_list = [], [], [], []\n",
    "\n",
    "# Compute per-class precision, recall, f1-score, accuracy\n",
    "for i, label in enumerate(class_names):\n",
    "    tn, fp, fn, tp = multi_cm[i].ravel()  # Extract TN, FP, FN, TP\n",
    "\n",
    "    # Compute Metrics\n",
    "    precision = tp / (tp + fp + 1e-8)  # Avoid division by zero\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-8)\n",
    "\n",
    "    # Append to lists\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "# **Compute Exact Match Accuracy**\n",
    "exact_match = accuracy_score(all_true_labels, all_pred_labels)  # Computes exact match accuracy\n",
    "\n",
    "# Create DataFrame\n",
    "df_metrics = pd.DataFrame({\n",
    "    \"Class\": class_names,\n",
    "    \"Precision\": precision_list,\n",
    "    \"Recall\": recall_list,\n",
    "    \"F1-Score\": f1_list,\n",
    "    \"Accuracy\": accuracy_list\n",
    "})\n",
    "\n",
    "# Add a row for Exact Match Accuracy (overall model accuracy)\n",
    "df_metrics.loc[len(df_metrics)] = [\"Exact Match Accuracy\", \"\", \"\", \"\", exact_match]\n",
    "\n",
    "df_metrics.to_csv(\"../results/df/df_metrics_overall.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
